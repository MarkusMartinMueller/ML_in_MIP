{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Pointnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:19:51.030119Z",
     "start_time": "2021-07-04T20:19:19.264982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/group/cake/leo/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#It should be possible to run the notebook independent of anything else. \n",
    "# If dependency cannot be installed via pip, either:\n",
    "# - download & install it via %%bash\n",
    "# - atleast mention those dependecies in this section\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q -e ../../utils/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:19:57.516766Z",
     "start_time": "2021-07-04T20:19:51.034729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /group/cake/leo/.venv/lib/python3.8/site-packages (4.60.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/group/cake/leo/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:19:59.762822Z",
     "start_time": "2021-07-04T20:19:57.520567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Recursion Depth\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import comet_ml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn.plotting as nip\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import git\n",
    "\n",
    "\n",
    "# Project utils\n",
    "\n",
    "import aneurysm_utils\n",
    "from aneurysm_utils import evaluation, training\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "%config InlineBackend.figure_format='retina'  # adapt plots for retina displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:19:59.837842Z",
     "start_time": "2021-07-04T20:19:59.765351Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"workspace\" in os.getcwd():\n",
    "    ROOT = \"/workspace\"\n",
    "elif \"/group/cake\" in os.getcwd(): \n",
    "    ROOT = \"/group/cake\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:19:59.925917Z",
     "start_time": "2021-07-04T20:19:59.840199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Info:\n",
      "\n",
      "Library Version: 0.1.0\n",
      "Configured Project: our-git-project\n",
      "\n",
      "Folder Structure: \n",
      "- Root folder: /group/cake\n",
      " - Project folder: /group/cake/our-git-project\n",
      " - Datasets folder: /data/training\n",
      " - Models folder: /group/cake/our-git-project/models\n",
      " - Experiments folder: /group/cake/our-git-project/experiments\n"
     ]
    }
   ],
   "source": [
    "env = aneurysm_utils.Environment(project=\"our-git-project\", root_folder=ROOT)\n",
    "env.cached_data[\"comet_key\"] = \"EGrR4luSis87yhHbs2rEaqAWs\" \n",
    "env.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "98\n",
      "         Images\n",
      "-----  --------\n",
      "All         109\n",
      "Train        87\n",
      "Val          11\n",
      "Test         11\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4042019554b475ebcef6e14ce0ceea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e900a02bccd49e1b9489d3e574ed2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973dff2ababe42778c7f9be0dad0be96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define dataset and preprocessing parameters\n",
    "dataset_params = {\n",
    "    \"prediction\": \"mask\",\n",
    "    \"mri_data_selection\": \"\", \n",
    "    \"balance_data\": False,\n",
    "    \"seed\": 1,\n",
    "    \"resample_voxel_dim\": (2.0,2.0,2.0),\n",
    "    \n",
    "}\n",
    "\n",
    "preprocessing_params = {\n",
    "    'min_max_normalize': True,\n",
    "    'mean_std_normalize': False,\n",
    "    'smooth_img': False, # can contain a number: smoothing factor\n",
    "    'intensity_segmentation': 0.2\n",
    "}\n",
    "\n",
    "from aneurysm_utils.data_collection import load_aneurysm_dataset\n",
    "\n",
    "df = load_aneurysm_dataset(\n",
    "    env,\n",
    "    mri_data_selection=dataset_params[\"mri_data_selection\"],\n",
    "    random_state=dataset_params[\"seed\"]\n",
    ")\n",
    "df.head()\n",
    "\n",
    "# Load MRI images and split into train, test, and validation\n",
    "from aneurysm_utils.data_collection import split_mri_images\n",
    "\n",
    "\n",
    "train_data, test_data, val_data, _ = split_mri_images(\n",
    "    env, \n",
    "    df, \n",
    "    prediction=dataset_params[\"prediction\"], \n",
    "    encode_labels=False,\n",
    "    random_state=dataset_params[\"seed\"],\n",
    "    balance_data=dataset_params[\"balance_data\"],\n",
    "    resample_voxel_dim=dataset_params[\"resample_voxel_dim\"],\n",
    "    #resample_size=dataset_params[\"resample_size\"]\n",
    ")\n",
    "\n",
    "mri_imgs_train, labels_train,_  = train_data\n",
    "mri_imgs_test, labels_test,_  = test_data\n",
    "mri_imgs_val, labels_val,_  = val_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T20:25:10.357103Z",
     "start_time": "2021-07-04T20:25:10.283054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common:\n",
      "(70, 70, 60):      80\n",
      "(35, 35, 31):       2\n",
      "(36, 36, 30):       2\n",
      "(55, 55, 49):       2\n",
      "(36, 36, 31):       1\n"
     ]
    }
   ],
   "source": [
    "#get most common shape\n",
    "from aneurysm_utils import preprocessing\n",
    "\n",
    "most_common_shape=preprocessing.check_mri_shapes(mri_imgs_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T13:22:19.421529Z",
     "start_time": "2021-06-16T13:22:19.203785Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing: Min Max Normalize...\n",
      "[INFO] Preprocessing: Intensity Segmentation...\n"
     ]
    }
   ],
   "source": [
    "from aneurysm_utils import preprocessing\n",
    "\n",
    "size_of_train = len(mri_imgs_train)\n",
    "size_of_test = len(mri_imgs_test)\n",
    "size_of_val = len(mri_imgs_val)\n",
    "\n",
    "# preprocess all lists as one to have a working mean_std_normalization\n",
    "mri_imgs = mri_imgs_train + mri_imgs_test + mri_imgs_val\n",
    "mri_imgs = preprocessing.preprocess(env, mri_imgs, preprocessing_params)\n",
    "\n",
    "mri_imgs_train = mri_imgs[:size_of_train]\n",
    "mri_imgs_train = [train for train in mri_imgs_train]\n",
    "mri_imgs_test = mri_imgs[size_of_train : size_of_train + size_of_test]\n",
    "mri_imgs_test = [test for test in mri_imgs_test]\n",
    "mri_imgs_val = mri_imgs[size_of_train + size_of_test :]\n",
    "mri_imgs_val = [val for val in mri_imgs_val]\n",
    "\n",
    "# preprocess mask\n",
    "x, y, h = labels_train[0].shape\n",
    "labels_train = [label_train for label_train in labels_train]\n",
    "labels_test = [label_test for label_test in labels_test]\n",
    "labels_val = [label_val for label_val in labels_val]\n",
    "# flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:54.553912Z",
     "start_time": "2021-06-14T16:20:54.468605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 70, 60)\n",
      "Most common:\n",
      "(70, 70, 60):      80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 70, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = most_common_shape#(93, 93, 80)  #(139, 139, 120)#(47,47,41)#\n",
    "print(size)\n",
    "train_index = [i for i, e in enumerate(mri_imgs_train) if e.shape != size]\n",
    "mri_imgs_train = [i for j, i in enumerate(mri_imgs_train) if j not in train_index]\n",
    "labels_train = [i for j, i in enumerate(labels_train) if j not in train_index]\n",
    "\n",
    "test_index = [i for i, e in enumerate(mri_imgs_test) if e.shape != size]\n",
    "mri_imgs_test = [i for j, i in enumerate(mri_imgs_test) if j not in test_index]\n",
    "labels_test = [i for j, i in enumerate(labels_test) if j not in test_index]\n",
    "\n",
    "val_index = [i for i, e in enumerate(mri_imgs_val) if e.shape != size]\n",
    "mri_imgs_val = [i for j, i in enumerate(mri_imgs_val) if j not in val_index]\n",
    "labels_val = [i for j, i in enumerate(labels_val) if j not in val_index]\n",
    "\n",
    "mri_imgs_train[0].shape\n",
    "preprocessing.check_mri_shapes(mri_imgs_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Implementation, configuration, and evaluation of the experiment.\n",
    "\n",
    "### Train Deep Model 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T13:23:00.518160Z",
     "start_time": "2021-06-16T13:22:59.156749Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=84815cc0af994054b5452060fe57ae28\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 'infinite', 'endTime': None, 'id': '84815cc0af994054b5452060fe57ae28', 'lastUpdateTime': None, 'maxCombo': 0, 'name': '84815cc0af994054b5452060fe57ae28', 'parameters': {'learning_rate': {'max': 0.01, 'min': 0.0001, 'scalingType': 'loguniform', 'type': 'float'}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'bal_acc', 'minSampleSize': 100, 'objective': 'maximize', 'retryAssignLimit': 0, 'retryLimit': 1000}, 'startTime': 15621022982, 'state': {'mode': None, 'seed': None, 'sequence': [], 'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0, 'sequence_retry_count': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '2.0.1'}\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Optimizer\n",
    "\n",
    "artifacts = {\n",
    "    \"train_data\": (mri_imgs_train, labels_train),\n",
    "    \"val_data\": (mri_imgs_val, labels_val),\n",
    "    \"test_data\": (mri_imgs_test, labels_test)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 1000,\n",
    "    \"learning_rate\": 2.6e-5, # 3e-04, 1.0E-5\n",
    "    \"es_patience\": None, # None = deactivate early stopping\n",
    "    \"weight_decay\": 0.000003, # 1e-3\n",
    "    \"model_name\": 'SegNet',\n",
    "    \"optimizer_momentum\": 0.9,\n",
    "    \"optimizer\":'Adam',\n",
    "    \"criterion\": \"CrossEntropyLoss\", \n",
    "    \"criterion_weights\": [1.0, 30.0], # [1.75, 1.0],\n",
    "    \"sampler\": None,   #'ImbalancedDatasetSampler2',\n",
    "    \"shuffle_train_set\": True,\n",
    "    \"save_models\":True,\n",
    "    \"scheduler\": \"ReduceLROnPlateau\", # \"ReduceLROnP\n",
    "    \"debug\":False,\n",
    "    \"dropout\":0.38,\n",
    "    \"start_radius\":7.254,\n",
    "    \"sample_rate1\": 0.2263,\n",
    "    \"sample_rate2\": 0.2941,\n",
    "    \n",
    "    \"save_models\":True,\n",
    "    \"process\": True,\n",
    "    \n",
    "}\n",
    "params.update(dataset_params)\n",
    "params.update(preprocessing_params)\n",
    "#in these config dictionary you can uncomment and change the parameters that should be optimized\n",
    "config = {\n",
    "    # We pick the Bayes algorithm:\n",
    "    \"algorithm\": \"bayes\",\n",
    "    # Declare your hyperparameters in the Vizier-inspired format:\n",
    "    \"parameters\": {\n",
    "        #\"criterion_weights\": {\"type\": \"integer\", \"scalingType\": \"loguniform\", \"min\": 1, \"max\": 10},\n",
    "        #\"weight_decay\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-10, \"max\": 1e-3},\n",
    "        \"learning_rate\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-4, \"max\": 1e-2},\n",
    "        #\"scheduler\": {\"type\": \"categorical\", \"values\": [\"ReduceLROnPlateau\", \"\"],},\n",
    "        #\"start_radius\":{\"type\":\"float\",\"scalingType\":\"loguniform\",\"min\":0.1, \"max\":0.2},\n",
    "    },\n",
    "    # Declare what we will be optimizing, and how:\n",
    "    \"spec\": {\"metric\": \"bal_acc\", \"objective\": \"maximize\"},  #test balance accuracy\n",
    "}\n",
    "\n",
    "\n",
    "opt = Optimizer(config, api_key=env.cached_data[\"comet_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect garbage\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-16T13:23:10.524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/rbendias/our-git-project/301d3f49c82c4e72bf9413d27858d230\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<comet_ml.Experiment object at 0x7f5568255d00>\n",
      "[INFO] Experiment mask-pytorch-SegNet is initialized.\n",
      "[INFO] Running experiment: 2021-07-21-16-34-27_mask-pytorch-segnet\n",
      "Number of Classes 2\n",
      "Selected model: SegNet\n"
     ]
    }
   ],
   "source": [
    "# Finally, get experiments, and train your models, also uncomment or add coresponding entries to param_copy\n",
    "# that should be optimzied\n",
    "import time\n",
    "for comet_exp in opt.get_experiments(project_name=env.project):\n",
    "    print(comet_exp)\n",
    "    param_copy = params.copy()\n",
    "    comet_exp.params\n",
    "    \n",
    "    #param_copy[\"weight_decay\"] = comet_exp.get_parameter(\"weight_decay\")\n",
    "    #param_copy[\"criterion_weights\"] = comet_exp.get_parameter(\"criterion_weights\")\n",
    "    param_copy[\"learning_rate\"] = comet_exp.get_parameter(\"learning_rate\")\n",
    "    #param_copy[\"scheduler\"] = comet_exp.get_parameter(\"scheduler\")\n",
    "\n",
    "    exp = env.create_experiment(\n",
    "        params[\"prediction\"] + \"-pytorch-\" + params[\"model_name\"], comet_exp\n",
    "    ) #params[\"selected_label\"] + \"-hyperopt-\" + params[\"model_name\"]\n",
    "    exp.run(training.train_pytorch_model, param_copy, artifacts)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    del exp\n",
    "    import gc\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "tab_nine_terminal",
   "language": "python",
   "name": "exploration-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
