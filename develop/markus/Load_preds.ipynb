{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c7fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/group/cake/markus/.venv/lib/python3.8/site-packages/nilearn/datasets/__init__.py:86: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Recursion Depth\n",
    "sys.setrecursionlimit(1000000000)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import comet_ml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn.plotting as nip\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "%config InlineBackend.figure_format='retina'  # adapt plots for retina displays\n",
    "import git\n",
    "import aneurysm_utils.evaluation as evaluation\n",
    "\n",
    "# Project utils\n",
    "\n",
    "import aneurysm_utils\n",
    "from aneurysm_utils import evaluation, training,preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af44348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_alternativ(image, patch_size,most_common_shape):\n",
    "    \"\"\"\n",
    "    image: numpy.array\n",
    "          shape is (number_of_patches,h,w,d) , number_of_patches,heigth,width,depth\n",
    "    patch_size: int\n",
    "            e.g. 64\n",
    "    most_common_shape: tuple\n",
    "                for example(139,139,120)\n",
    "\n",
    "    Return\n",
    "\n",
    "    image: np.array\n",
    "\n",
    "          unified and unpatch image, shape (most_common_shape)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    number_of_patches,heigth,width,depth = image.shape\n",
    "\n",
    "    dim = np.array(most_common_shape)# size of the image\n",
    "    n_patches = np.ceil(dim/patch_size).astype(int) # calculates the number of patches for each dim, to cover all voxel at least once in form e.g[3,3,2]\n",
    "    rest  = n_patches * patch_size%dim ## calculates number of entries for each dimension which overlapp, means for example n_patches = 18 and 64 we have rest = 53\n",
    "    \n",
    "    h,w,d = most_common_shape\n",
    "\n",
    "    ## initializing empty array for the unified image\n",
    "    unified_image =  np.zeros([h,w,d])\n",
    "\n",
    "    counter = 0 ## counter for patches\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in range(n_patches[0]):\n",
    "\n",
    "        if i == n_patches[0]-1: ## only the last cube is an overlapped cube\n",
    "          start_x = i*patch_size-rest[0]\n",
    "          stop_x= (i+1)* patch_size-rest[0]\n",
    "\n",
    "        else:    \n",
    "          start_x = i*patch_size\n",
    "          stop_x = (i+1)* patch_size\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(n_patches[1]):\n",
    "            if j == n_patches[1]-1: ## only the last cube is an overlapped cube\n",
    "                start_y = j*patch_size-rest[1]\n",
    "                stop_y= (j+1)* patch_size-rest[1]\n",
    "\n",
    "            else:    \n",
    "                start_y = j*patch_size\n",
    "                stop_y = (j+1)* patch_size\n",
    "\n",
    "            for k in range(n_patches[2]):\n",
    "                if k == n_patches[2]-1: \n",
    "                    start_z = k*patch_size-rest[2]\n",
    "                    stop_z = (k+1)* patch_size-rest[2]\n",
    "\n",
    "                else:    \n",
    "                    start_z = k*patch_size\n",
    "                    stop_z = (k+1)* patch_size\n",
    "\n",
    "\n",
    "              ##maximum between channel one or two, probably not necessary\n",
    "              #max_class = np.maximum(image[n,0,:,:,:],image[n,1,:,:,:])\n",
    "\n",
    "              ###includes overlapping case\n",
    "              #unified_image[start_x:stop_x,start_y:stop_y,start_z:stop_z] = np.maximum(unified_image[start_x:stop_x,start_y:stop_y,start_z:stop_z],max_class)\n",
    "                unified_image[start_x:stop_x,start_y:stop_y,start_z:stop_z] = np.maximum(unified_image[start_x:stop_x,start_y:stop_y,start_z:stop_z],image[counter,:,:,:])\n",
    "                \n",
    "                counter+=1## next patch\n",
    "                \n",
    "                if (counter== number_of_patches):\n",
    "                    break;\n",
    "    \n",
    "    return unified_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea7719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_unifier_alternativ(list_patches,size_test_set,most_common_shape,patch_size):\n",
    "  \"\"\"\n",
    "  list_patches: list\n",
    "                containing predictions from the evaluations, length should be number_of_patches x length_test_set\n",
    "                each element should have the form (h,w,d)\n",
    "  size_test_set: int\n",
    "\n",
    "  most_common_shape: tuple\n",
    "                most_common shape from the original input images before patchifying\n",
    "  \n",
    "  patch_size: int\n",
    "\n",
    "\n",
    "\n",
    "  Return:\n",
    "\n",
    "  unified_images: list\n",
    "                contains the unpatched images \n",
    "                each element has the shape:(most_common_shape) \n",
    "\n",
    "  \"\"\"\n",
    "  \n",
    "  dim = np.array(most_common_shape)\n",
    "  n_patches = np.ceil(dim/patch_size).astype(int)# output is number of patches per dimension\n",
    "\n",
    "  number_of_patches = np.prod(n_patches)# number of patches overall\n",
    "\n",
    "  h,w,d = most_common_shape\n",
    "  \n",
    "  unified_images = []\n",
    "  assert (len(list_patches)/(number_of_patches))== size_test_set\n",
    "  \n",
    "\n",
    "  ##output list: each element has the form (number_of_patches,n_classes,h,w,d)\n",
    "  images = np.split(np.array(list_patches),size_test_set)  \n",
    "\n",
    "  for n in range(size_test_set):\n",
    "        \n",
    "        unified_images.append(unify_alternativ(images[n],patch_size,most_common_shape))\n",
    "  assert len(unified_images) == size_test_set\n",
    "  return unified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347ee8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(\"/group/cake/our-git-project/develop/markus/preds_unet_fs1_320.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cecc568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dimension 1: two entries first one are masks, second on the logits\n",
    "\n",
    "converter = map(lambda x: x[0], predictions)\n",
    "preds = list(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3e6ce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patch_unifier_alternativ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4de013406ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#most_commen_shape with 1.2 voxdim is 116,116,100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_unifier_alternativ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m116\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'patch_unifier_alternativ' is not defined"
     ]
    }
   ],
   "source": [
    "## inputs:   list_patches,size_test_set,most_common_shape,patch_size\n",
    "\n",
    "#most_commen_shape with 1.2 voxdim is 116,116,100\n",
    "\n",
    "uni = patch_unifier_alternativ(preds,9,(116,116,100),64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Working env",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
