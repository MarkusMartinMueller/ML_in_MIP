{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c6ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936ada23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init_type='normal'):\n",
    "    #print('initialization method [%s]' % init_type)\n",
    "    if init_type == 'normal':\n",
    "        net.apply(weights_init_normal)\n",
    "    elif init_type == 'xavier':\n",
    "        net.apply(weights_init_xavier)\n",
    "    elif init_type == 'kaiming':\n",
    "        net.apply(weights_init_kaiming)\n",
    "    else:\n",
    "        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "      #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "            init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "            init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "            init.normal(m.weight.data, 1.0, 0.02)\n",
    "            init.constant(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_normal(m.weight.data, gain=1)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.xavier_normal(m.weight.data, gain=1)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal(m.weight.data, 1.0, 0.02)\n",
    "        init.constant(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.normal(m.weight.data, 1.0, 0.02)\n",
    "        init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _GridAttentionBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, gating_channels, inter_channels=None, dimension=3, mode='concatenation',\n",
    "                 sub_sample_factor=(2,2,2)):\n",
    "        super(_GridAttentionBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [2, 3]\n",
    "        assert mode in ['concatenation']\n",
    "\n",
    "        # Downsampling rate for the input featuremap\n",
    "        if isinstance(sub_sample_factor, tuple): self.sub_sample_factor = sub_sample_factor\n",
    "        elif isinstance(sub_sample_factor, list): self.sub_sample_factor = tuple(sub_sample_factor)\n",
    "        else: self.sub_sample_factor = tuple([sub_sample_factor]) * dimension\n",
    "\n",
    "        # Default parameter set\n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "        self.sub_sample_kernel_size = self.sub_sample_factor\n",
    "\n",
    "        # Number of channels (pixel dimensions)\n",
    "        self.in_channels = in_channels\n",
    "        self.gating_channels = gating_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            bn = nn.BatchNorm3d\n",
    "            self.upsample_mode = 'trilinear'\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        # Output transform\n",
    "        self.W = nn.Sequential(\n",
    "            conv_nd(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0),\n",
    "            bn(self.in_channels),\n",
    "        )\n",
    "\n",
    "        # Theta^T * x_ij + Phi^T * gating_signal + bias\n",
    "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
    "                             kernel_size=self.sub_sample_kernel_size, stride=self.sub_sample_factor, padding=0, bias=False)\n",
    "        self.phi = conv_nd(in_channels=self.gating_channels, out_channels=self.inter_channels,\n",
    "                           kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.psi = conv_nd(in_channels=self.inter_channels, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        # Initialise weights\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "        # Define the operation\n",
    "        if mode == 'concatenation':\n",
    "            self.operation_function = self._concatenation\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown operation function.')\n",
    "\n",
    "\n",
    "    def forward(self, x, g):\n",
    "        '''\n",
    "        :param x: (b, c, t, h, w)\n",
    "        :param g: (b, g_d)\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        output = self.operation_function(x, g)\n",
    "        return output\n",
    "\n",
    "    def _concatenation(self, x, g):\n",
    "        input_size = x.size()\n",
    "        batch_size = input_size[0]\n",
    "        assert batch_size == g.size(0)\n",
    "\n",
    "        # theta => (b, c, t, h, w) -> (b, i_c, t, h, w) -> (b, i_c, thw)\n",
    "        # phi   => (b, g_d) -> (b, i_c)\n",
    "        theta_x = self.theta(x)\n",
    "        theta_x_size = theta_x.size()\n",
    "\n",
    "        # g (b, c, t', h', w') -> phi_g (b, i_c, t', h', w')\n",
    "        #  Relu(theta_x + phi_g + bias) -> f = (b, i_c, thw) -> (b, i_c, t/s1, h/s2, w/s3)\n",
    "        phi_g = F.upsample(self.phi(g), size=theta_x_size[2:], mode=self.upsample_mode)\n",
    "        f = F.relu(theta_x + phi_g, inplace=True)\n",
    "\n",
    "        #  psi^T * f -> (b, psi_i_c, t/s1, h/s2, w/s3)\n",
    "        sigm_psi_f = torch.sigmoid(self.psi(f))\n",
    "\n",
    "        # upsample the attentions and multiply\n",
    "        sigm_psi_f = F.upsample(sigm_psi_f, size=input_size[2:], mode=self.upsample_mode)\n",
    "        y = sigm_psi_f.expand_as(x) * x\n",
    "        W_y = self.W(y)\n",
    "\n",
    "        return W_y, sigm_psi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c1b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridAttentionBlock3D(_GridAttentionBlockND):\n",
    "    def __init__(self, in_channels, gating_channels, inter_channels=None, mode='concatenation',\n",
    "                 sub_sample_factor=(2,2,2)):\n",
    "        super(GridAttentionBlock3D, self).__init__(in_channels,\n",
    "                                                   inter_channels=inter_channels,\n",
    "                                                   gating_channels=gating_channels,\n",
    "                                                   dimension=3, mode=mode,\n",
    "                                                   sub_sample_factor=sub_sample_factor,\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3cdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetConv3(nn.Module):\n",
    "    def __init__(self, in_size, out_size, is_batchnorm, kernel_size=(3,3,1), padding_size=(1,1,0), init_stride=(1,1,1)):\n",
    "        super(UnetConv3, self).__init__()\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, out_size, kernel_size, init_stride, padding_size),\n",
    "                                       nn.BatchNorm3d(out_size),\n",
    "                                       nn.ReLU(inplace=True),)\n",
    "            self.conv2 = nn.Sequential(nn.Conv3d(out_size, out_size, kernel_size, 1, padding_size),\n",
    "                                       nn.BatchNorm3d(out_size),\n",
    "                                       nn.ReLU(inplace=True),)\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, out_size, kernel_size, init_stride, padding_size),\n",
    "                                       nn.ReLU(inplace=True),)\n",
    "            self.conv2 = nn.Sequential(nn.Conv3d(out_size, out_size, kernel_size, 1, padding_size),\n",
    "                                       nn.ReLU(inplace=True),)\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class UnetGatingSignal3(nn.Module):\n",
    "    def __init__(self, in_size, out_size, is_batchnorm):\n",
    "        super(UnetGatingSignal3, self).__init__()\n",
    "        self.fmap_size = (4, 4, 4)\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, in_size//2, (1,1,1), (1,1,1), (0,0,0)),\n",
    "                                       nn.BatchNorm3d(in_size//2),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.AdaptiveAvgPool3d(output_size=self.fmap_size),\n",
    "                                       )\n",
    "            self.fc1 = nn.Linear(in_features=(in_size//2) * self.fmap_size[0] * self.fmap_size[1] * self.fmap_size[2],\n",
    "                                 out_features=out_size, bias=True)\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, in_size//2, (1,1,1), (1,1,1), (0,0,0)),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.AdaptiveAvgPool3d(output_size=self.fmap_size),\n",
    "                                       )\n",
    "            self.fc1 = nn.Linear(in_features=(in_size//2) * self.fmap_size[0] * self.fmap_size[1] * self.fmap_size[2],\n",
    "                                 out_features=out_size, bias=True)\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = outputs.view(batch_size, -1)\n",
    "        outputs = self.fc1(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class UnetGridGatingSignal3(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size=(1,1,1), is_batchnorm=True):\n",
    "        super(UnetGridGatingSignal3, self).__init__()\n",
    "\n",
    "        if is_batchnorm:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, out_size, kernel_size, (1,1,1), (0,0,0)),\n",
    "                                       nn.BatchNorm3d(out_size),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(nn.Conv3d(in_size, out_size, kernel_size, (1,1,1), (0,0,0)),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       )\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UnetUp3(nn.Module):\n",
    "    def __init__(self, in_size, out_size, is_deconv, is_batchnorm=True):\n",
    "        super(UnetUp3, self).__init__()\n",
    "        if is_deconv:\n",
    "            self.conv = UnetConv3(in_size, out_size, is_batchnorm)\n",
    "            self.up = nn.ConvTranspose3d(in_size, out_size, kernel_size=(4,4,1), stride=(2,2,1), padding=(1,1,0))\n",
    "        else:\n",
    "            self.conv = UnetConv3(in_size+out_size, out_size, is_batchnorm)\n",
    "            self.up = nn.Upsample(scale_factor=(2, 2, 1), mode='trilinear')\n",
    "\n",
    "        # initialise the blocks\n",
    "        for m in self.children():\n",
    "            if m.__class__.__name__.find('UnetConv3') != -1: continue\n",
    "            init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs1, inputs2):\n",
    "        outputs2 = self.up(inputs2)\n",
    "        offset = outputs2.size()[2] - inputs1.size()[2]\n",
    "        padding = 2 * [offset // 2, offset // 2, 0]\n",
    "        outputs1 = F.pad(inputs1, padding)\n",
    "        return self.conv(torch.cat([outputs1, outputs2], 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930fa795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class unet_grid_attention_3D(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_scale=4, n_classes=2, is_deconv=True, in_channels=1,\n",
    "                 nonlocal_mode='concatenation', attention_dsample=(2,2,2), is_batchnorm=True):\n",
    "        super(unet_grid_attention_3D, self).__init__()\n",
    "        self.is_deconv = is_deconv\n",
    "        self.in_channels = in_channels\n",
    "        self.is_batchnorm = is_batchnorm\n",
    "        self.feature_scale = feature_scale\n",
    "\n",
    "        filters = [64, 128, 256]# ,512, 1024]\n",
    "        filters = [int(x / self.feature_scale) for x in filters]\n",
    "\n",
    "        # downsampling\n",
    "        self.conv1 = UnetConv3(self.in_channels, filters[0], self.is_batchnorm)\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=(2, 2, 1))\n",
    "\n",
    "        self.conv2 = UnetConv3(filters[0], filters[1], self.is_batchnorm)\n",
    "        self.maxpool2 = nn.MaxPool3d(kernel_size=(2, 2, 1))\n",
    "\n",
    "        #self.conv3 = UnetConv3(filters[1], filters[2], self.is_batchnorm)\n",
    "        #self.maxpool3 = nn.MaxPool3d(kernel_size=(2, 2, 1))\n",
    "\n",
    "        #self.conv4 = UnetConv3(filters[2], filters[3], self.is_batchnorm)\n",
    "        #self.maxpool4 = nn.MaxPool3d(kernel_size=(2, 2, 1))\n",
    "\n",
    "        self.center = UnetConv3(filters[1], filters[2], self.is_batchnorm)\n",
    "        self.gating = UnetGridGatingSignal3(filters[2], filters[1], kernel_size=(1, 1, 1), is_batchnorm=self.is_batchnorm)\n",
    "\n",
    "        # attention blocks\n",
    "        self.attentionblock2 = GridAttentionBlock3D(in_channels=filters[1], gating_channels=filters[1],\n",
    "                                                    inter_channels=filters[1], sub_sample_factor=attention_dsample, mode=nonlocal_mode)\n",
    "        #self.attentionblock3 = GridAttentionBlock3D(in_channels=filters[2], gating_channels=filters[3],\n",
    "                                                    #inter_channels=filters[2], sub_sample_factor=attention_dsample, mode=nonlocal_mode)\n",
    "        #self.attentionblock4 = GridAttentionBlock3D(in_channels=filters[3], gating_channels=filters[3],\n",
    "                                                    #inter_channels=filters[3], sub_sample_factor=attention_dsample, mode=nonlocal_mode)\n",
    "\n",
    "        # upsampling\n",
    "        #self.up_concat4 = UnetUp3(filters[4], filters[3], self.is_deconv, self.is_batchnorm)\n",
    "        #self.up_concat3 = UnetUp3(filters[3], filters[2], self.is_deconv, self.is_batchnorm)\n",
    "        self.up_concat2 = UnetUp3(filters[2], filters[1], self.is_deconv, self.is_batchnorm)\n",
    "        self.up_concat1 = UnetUp3(filters[1], filters[0], self.is_deconv, self.is_batchnorm)\n",
    "\n",
    "        # final conv (without any concat)\n",
    "        self.final = nn.Conv3d(filters[0], n_classes, 1)\n",
    "\n",
    "        # initialise weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Feature Extraction\n",
    "        conv1 = self.conv1(inputs)\n",
    "        maxpool1 = self.maxpool1(conv1)\n",
    "\n",
    "        conv2 = self.conv2(maxpool1)\n",
    "        maxpool2 = self.maxpool2(conv2)\n",
    "\n",
    "        #conv3 = self.conv3(maxpool2)\n",
    "        #maxpool3 = self.maxpool3(conv3)\n",
    "\n",
    "        #conv4 = self.conv4(maxpool3)\n",
    "        #maxpool4 = self.maxpool4(conv4)\n",
    "\n",
    "        # Gating Signal Generation\n",
    "        center = self.center(maxpool2)\n",
    "        gating = self.gating(center)\n",
    "        \n",
    "        # Attention Mechanism\n",
    "        #g_conv4, att4 = self.attentionblock4(conv4, gating)\n",
    "        #g_conv3, att3 = self.attentionblock3(conv3, gating)\n",
    "        g_conv2, att2 = self.attentionblock2(conv2, gating)\n",
    "\n",
    "        # Upscaling Part (Decoder)\n",
    "        #up4 = self.up_concat4(g_conv4, center)\n",
    "        #up3 = self.up_concat3(g_conv3, up4)\n",
    "        up2 = self.up_concat2(g_conv2, center)\n",
    "        up1 = self.up_concat1(conv1, up2)\n",
    "\n",
    "        final = self.final(up1)\n",
    "\n",
    "        return final\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0417c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    x = torch.rand((3,1,64,64,64)) ## batch,channel,height,width,depth\n",
    "    \n",
    "    model = unet_grid_attention_3D(feature_scale=4, n_classes=2, is_deconv=True, in_channels=1,nonlocal_mode='concatenation', attention_dsample=(2,2,2), is_batchnorm=True)\n",
    "    preds = model(x)\n",
    "    \n",
    "    print(preds.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7900a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-2749b11c82a7>:17: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
      "<ipython-input-2-2749b11c82a7>:21: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, 1.0, 0.02)\n",
      "<ipython-input-2-2749b11c82a7>:22: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias.data, 0.0)\n",
      "/group/cake/markus/.venv/lib/python3.8/site-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/group/cake/markus/.venv/lib/python3.8/site-packages/torch/nn/functional.py:3454: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Exploration Tutorial",
   "language": "python",
   "name": "exploration-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
