{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Template\n",
    "\n",
    "\n",
    "**In this notebook:**\n",
    "\n",
    "* Template with comet ml optimizer \n",
    "\n",
    "**Todo:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Install, load, and initialize all required dependencies for this experiment.\n",
    "\n",
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:03:54.761597Z",
     "start_time": "2021-06-14T16:00:27.572240Z"
    }
   },
   "outputs": [],
   "source": [
    "#It should be possible to run the notebook independent of anything else. \n",
    "# If dependency cannot be installed via pip, either:\n",
    "# - download & install it via %%bash\n",
    "# - atleast mention those dependecies in this section\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q -e ../../utils/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:27.999665Z",
     "start_time": "2021-06-14T16:20:27.912162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Recursion Depth\n",
    "sys.setrecursionlimit(1000000000)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import comet_ml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn.plotting as nip\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "%config InlineBackend.figure_format='retina'  # adapt plots for retina displays\n",
    "import git\n",
    "\n",
    "\n",
    "# Project utils\n",
    "\n",
    "import aneurysm_utils\n",
    "from aneurysm_utils import evaluation, training,preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:29.336695Z",
     "start_time": "2021-06-14T16:20:29.272932Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"workspace\" in os.getcwd():\n",
    "    ROOT = \"/workspace\" # local \n",
    "elif \"/group/cake\" in os.getcwd(): \n",
    "    ROOT = \"/group/cake\" # Jupyter Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:30.058122Z",
     "start_time": "2021-06-14T16:20:29.974521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Info:\n",
      "\n",
      "Library Version: 0.1.0\n",
      "Configured Project: our-git-project\n",
      "\n",
      "Folder Structure: \n",
      "- Root folder: /group/cake\n",
      " - Project folder: /group/cake/our-git-project\n",
      " - Datasets folder: /data/training\n",
      " - Models folder: /group/cake/our-git-project/models\n",
      " - Experiments folder: /group/cake/our-git-project/experiments\n"
     ]
    }
   ],
   "source": [
    "env = aneurysm_utils.Environment(project=\"our-git-project\", root_folder=ROOT)\n",
    "env.cached_data[\"comet_key\"] = \"EGrR4luSis87yhHbs2rEaqAWs\" \n",
    "env.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Download, explore, and prepare all required data for the experiment in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:30.450257Z",
     "start_time": "2021-06-14T16:20:30.387149Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    \"prediction\": \"mask\",\n",
    "    \"mri_data_selection\": \"\", \n",
    "    \"balance_data\": False,\n",
    "    \"seed\": 1,\n",
    "    \"resample_voxel_dim\": (1, 1, 1)\n",
    "}\n",
    "\n",
    "preprocessing_params = {\n",
    "    'min_max_normalize': True,\n",
    "    'mean_std_normalize': False,\n",
    "    'smooth_img': False, # can contain a number: smoothing factor\n",
    "    'intensity_segmentation': 0.15\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:31.556885Z",
     "start_time": "2021-06-14T16:20:31.453478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aneurysm Geometry</th>\n",
       "      <th>Angiography Data</th>\n",
       "      <th>Vessel Geometry</th>\n",
       "      <th>Labeled Mask Index</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Rupture Status</th>\n",
       "      <th>Age Bin</th>\n",
       "      <th>Aneurysm Count</th>\n",
       "      <th>Case</th>\n",
       "      <th>Path Orig</th>\n",
       "      <th>Path Mask</th>\n",
       "      <th>Path Vessel</th>\n",
       "      <th>Path Labeled Mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001.stl</td>\n",
       "      <td>A001_orig.nii.gz</td>\n",
       "      <td>A001_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>Acom</td>\n",
       "      <td>48</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A001</td>\n",
       "      <td>/data/training/A001_orig.nii.gz</td>\n",
       "      <td>/data/training/A001_masks.nii.gz</td>\n",
       "      <td>/data/training/A001_vessel.nii.gz</td>\n",
       "      <td>/data/training/A001_labeledMasks.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A003.stl</td>\n",
       "      <td>A003_orig.nii.gz</td>\n",
       "      <td>A003_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>Pcom</td>\n",
       "      <td>58</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>1</td>\n",
       "      <td>A003</td>\n",
       "      <td>/data/training/A003_orig.nii.gz</td>\n",
       "      <td>/data/training/A003_masks.nii.gz</td>\n",
       "      <td>/data/training/A003_vessel.nii.gz</td>\n",
       "      <td>/data/training/A003_labeledMasks.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A005.stl</td>\n",
       "      <td>A005_orig.nii.gz</td>\n",
       "      <td>A005_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>PICA</td>\n",
       "      <td>45</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A005</td>\n",
       "      <td>/data/training/A005_orig.nii.gz</td>\n",
       "      <td>/data/training/A005_masks.nii.gz</td>\n",
       "      <td>/data/training/A005_vessel.nii.gz</td>\n",
       "      <td>/data/training/A005_labeledMasks.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A006.stl</td>\n",
       "      <td>A006_orig.nii.gz</td>\n",
       "      <td>A006_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>ACom</td>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A006</td>\n",
       "      <td>/data/training/A006_orig.nii.gz</td>\n",
       "      <td>/data/training/A006_masks.nii.gz</td>\n",
       "      <td>/data/training/A006_vessel.nii.gz</td>\n",
       "      <td>/data/training/A006_labeledMasks.nii.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A008.stl</td>\n",
       "      <td>A008_orig.nii.gz</td>\n",
       "      <td>A008_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>ACA</td>\n",
       "      <td>72</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(70, 80]</td>\n",
       "      <td>1</td>\n",
       "      <td>A008</td>\n",
       "      <td>/data/training/A008_orig.nii.gz</td>\n",
       "      <td>/data/training/A008_masks.nii.gz</td>\n",
       "      <td>/data/training/A008_vessel.nii.gz</td>\n",
       "      <td>/data/training/A008_labeledMasks.nii.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Aneurysm Geometry  Angiography Data  Vessel Geometry  Labeled Mask Index  \\\n",
       "0          A001.stl  A001_orig.nii.gz  A001_vessel.stl                   1   \n",
       "1          A003.stl  A003_orig.nii.gz  A003_vessel.stl                   1   \n",
       "2          A005.stl  A005_orig.nii.gz  A005_vessel.stl                   1   \n",
       "3          A006.stl  A006_orig.nii.gz  A006_vessel.stl                   1   \n",
       "4          A008.stl  A008_orig.nii.gz  A008_vessel.stl                   1   \n",
       "\n",
       "  Location  Age Sex  Rupture Status   Age Bin  Aneurysm Count  Case  \\\n",
       "0     Acom   48   m             1.0  (40, 50]               1  A001   \n",
       "1     Pcom   58   f             0.0  (50, 60]               1  A003   \n",
       "2     PICA   45   m             1.0  (40, 50]               1  A005   \n",
       "3     ACom   46   f             1.0  (40, 50]               1  A006   \n",
       "4      ACA   72   f             0.0  (70, 80]               1  A008   \n",
       "\n",
       "                         Path Orig                         Path Mask  \\\n",
       "0  /data/training/A001_orig.nii.gz  /data/training/A001_masks.nii.gz   \n",
       "1  /data/training/A003_orig.nii.gz  /data/training/A003_masks.nii.gz   \n",
       "2  /data/training/A005_orig.nii.gz  /data/training/A005_masks.nii.gz   \n",
       "3  /data/training/A006_orig.nii.gz  /data/training/A006_masks.nii.gz   \n",
       "4  /data/training/A008_orig.nii.gz  /data/training/A008_masks.nii.gz   \n",
       "\n",
       "                         Path Vessel                        Path Labeled Mask  \n",
       "0  /data/training/A001_vessel.nii.gz  /data/training/A001_labeledMasks.nii.gz  \n",
       "1  /data/training/A003_vessel.nii.gz  /data/training/A003_labeledMasks.nii.gz  \n",
       "2  /data/training/A005_vessel.nii.gz  /data/training/A005_labeledMasks.nii.gz  \n",
       "3  /data/training/A006_vessel.nii.gz  /data/training/A006_labeledMasks.nii.gz  \n",
       "4  /data/training/A008_vessel.nii.gz  /data/training/A008_labeledMasks.nii.gz  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aneurysm_utils.data_collection import load_aneurysm_dataset\n",
    "\n",
    "df = load_aneurysm_dataset(\n",
    "    env,\n",
    "    mri_data_selection=dataset_params[\"mri_data_selection\"],\n",
    "    random_state=dataset_params[\"seed\"]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Split MRI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:40.711578Z",
     "start_time": "2021-06-14T16:20:34.520886Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "98\n",
      "         Images\n",
      "-----  --------\n",
      "All         109\n",
      "Train        87\n",
      "Val          11\n",
      "Test         11\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7b4ab4221f4b7d8ae1b31883d5e253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe6c4f9720d48d2a7ccf7c24426065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489b359950a84836ad719aefac165a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MRI images and split into train, test, and validation\n",
    "from aneurysm_utils.data_collection import split_mri_images\n",
    "#case_list = [ \"A123\", \"A121\", \"A124\"] # \"A003\",\"A005\",\"A006\",\"A008\", \"A010\", \"A012\",\"A009\", \"A120\",\n",
    "#df = df.loc[df[\"Case\"].isin(case_list)]\n",
    "\n",
    "train_data, test_data, val_data, _ = split_mri_images(\n",
    "    env, \n",
    "    df, \n",
    "    prediction=dataset_params[\"prediction\"], \n",
    "    encode_labels=False,\n",
    "    random_state=dataset_params[\"seed\"],\n",
    "    balance_data=dataset_params[\"balance_data\"],\n",
    "    resample_voxel_dim=dataset_params[\"resample_voxel_dim\"]\n",
    ")\n",
    "\n",
    "mri_imgs_train, labels_train = train_data\n",
    "mri_imgs_test, labels_test = test_data\n",
    "mri_imgs_val, labels_val = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:40.777573Z",
     "start_time": "2021-06-14T16:20:40.714453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common:\n",
      "(139, 139, 120):      75\n",
      "(139, 139, 119):       5\n",
      "(70, 70, 60):       5\n",
      "(108, 108, 96):       2\n"
     ]
    }
   ],
   "source": [
    "from aneurysm_utils import preprocessing\n",
    "\n",
    "most_commen_shape = preprocessing.check_mri_shapes(mri_imgs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:54.553912Z",
     "start_time": "2021-06-14T16:20:54.468605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common:\n",
      "(139, 139, 120):      75\n",
      "(array([0., 1.], dtype=float32), array([2318414,     106]))\n"
     ]
    }
   ],
   "source": [
    "size = most_commen_shape  #(139, 139, 120)\n",
    "train_index = [i for i, e in enumerate(mri_imgs_train) if e.shape != size]\n",
    "mri_imgs_train = [i for j, i in enumerate(mri_imgs_train) if j not in train_index]\n",
    "labels_train = [i for j, i in enumerate(labels_train) if j not in train_index]\n",
    "\n",
    "test_index = [i for i, e in enumerate(mri_imgs_test) if e.shape != size]\n",
    "mri_imgs_test = [i for j, i in enumerate(mri_imgs_test) if j not in test_index]\n",
    "labels_test = [i for j, i in enumerate(labels_test) if j not in test_index]\n",
    "\n",
    "val_index = [i for i, e in enumerate(mri_imgs_val) if e.shape != size]\n",
    "mri_imgs_val = [i for j, i in enumerate(mri_imgs_val) if j not in val_index]\n",
    "labels_val = [i for j, i in enumerate(labels_val) if j not in val_index]\n",
    "\n",
    "mri_imgs_train[0].shape\n",
    "preprocessing.check_mri_shapes(mri_imgs_train)\n",
    "print(np.unique(labels_val[0], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_creater(image, patch_size, test = None):\n",
    "    \"\"\"\n",
    "    Creates overlapping patches from  preprocessed image, the number of patches is fixed to certain value\n",
    "    and the size can be changed as well\n",
    "    ----------\n",
    "    image: numpy.array\n",
    "        image which will be sliced into patches\n",
    "    patch_size: tuple of int\n",
    "        size of the patch, equal in each direction\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array  (n_patches,channels,patch_size,patch_size,patch_size)\n",
    "        list containing the patches\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    dim = np.array(image.shape)# size of the image\n",
    "    n_patches = np.ceil(dim/patch_size).astype(int) # calculates the number of patches for each dim, to cover all voxel at least once\n",
    "    rest  = n_patches * patch_size%dim ## calculates the remaining voxel which are going to overlap \n",
    "\n",
    "    patches = []\n",
    "    for i in range(n_patches[0]):\n",
    "        \n",
    "        if i == n_patches[0]-1: ## only the last cube is an overlapped cube\n",
    "            start_x = i*patch_size-rest[0]## indices were to start and stop the slicing true the image array\n",
    "            stop_x= (i+1)* patch_size-rest[0]\n",
    "              \n",
    "        else:    \n",
    "            start_x = i*patch_size\n",
    "            stop_x = (i+1)* patch_size\n",
    "\n",
    "        \n",
    "              \n",
    "        for j in range(n_patches[1]):\n",
    "            if j == n_patches[1]-1: ## only the last cube is an overlapped cube\n",
    "                start_y = j*patch_size-rest[1]\n",
    "                stop_y= (j+1)* patch_size-rest[1]\n",
    "              \n",
    "            else:    \n",
    "                start_y = j*patch_size\n",
    "                stop_y = (j+1)* patch_size\n",
    "            \n",
    "            for k in range(n_patches[2]):\n",
    "                if k == n_patches[2]-1: \n",
    "                    start_z = k*patch_size-rest[2]\n",
    "                    stop_z = (k+1)* patch_size-rest[2]\n",
    "              \n",
    "                else:    \n",
    "                    start_z = k*patch_size\n",
    "                    stop_z = (k+1)* patch_size\n",
    "\n",
    "                if test:\n",
    "                    \n",
    "                    patches.append(torch.from_numpy(image[start_x:stop_x,start_y:stop_y,start_z:stop_z]))\n",
    "                else:\n",
    "                    patches.append(image[start_x:stop_x,start_y:stop_y,start_z:stop_z])\n",
    "        \n",
    "    #return np.array([*patches])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_list(data,patch_size,test = None):\n",
    "    \"\"\"\n",
    "    data: numpy.array\n",
    "        containing dataset of dimensions (size_of_set,height,width,depth),e.g. (75,139,139,120)\n",
    "    patch_size: int\n",
    "    \n",
    "    Return\n",
    "    \n",
    "    list_patch: list\n",
    "        each element is one image of type numpy.array/torch.tensor with dimensions(n_classes,most_common_shape),\n",
    "    \"\"\"\n",
    "    list_patch = []\n",
    "\n",
    "    \n",
    "    for n in range(len(data)):\n",
    "        patch = patch_creater(data[n],patch_size,test)\n",
    "        list_patch = list_patch+patch\n",
    "    \n",
    "\n",
    "    return list_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing: Min Max Normalize...\n",
      "[INFO] Preprocessing: Intensity Segmentation...\n"
     ]
    }
   ],
   "source": [
    "from aneurysm_utils import preprocessing\n",
    "patch_size = 64\n",
    "size_of_train = len(mri_imgs_train)\n",
    "size_of_test = len(mri_imgs_test)\n",
    "size_of_val = len(mri_imgs_val)\n",
    "\n",
    "# preprocess all lists as one to have a working mean_std_normalization\n",
    "mri_imgs = mri_imgs_train + mri_imgs_test + mri_imgs_val\n",
    "mri_imgs = preprocessing.preprocess(env, mri_imgs, preprocessing_params)\n",
    "###creating patches\n",
    "mri_imgs_train = np.asarray(mri_imgs[:size_of_train])\n",
    "mri_imgs_train = patch_list(mri_imgs_train,patch_size)\n",
    "mri_imgs_test = np.asarray(mri_imgs[size_of_train : size_of_train + size_of_test])\n",
    "mri_imgs_test = patch_list(mri_imgs_test,patch_size)\n",
    "mri_imgs_val = np.asarray(mri_imgs[size_of_train + size_of_test :])\n",
    "mri_imgs_val = patch_list(mri_imgs_val,patch_size)\n",
    "\n",
    "# preprocess mask\n",
    "x, y, h = labels_train[0].shape\n",
    "labels_train = patch_list(labels_train,patch_size)\n",
    "labels_test = patch_list(labels_test,patch_size)\n",
    "labels_val = patch_list(labels_val,patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mri_imgs_train\n",
    "del mri_imgs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 64, 64), 1350, list, 162, list, 162)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_imgs_train[0].shape,len(mri_imgs_train),type(mri_imgs_test),len(mri_imgs_test),type(mri_imgs_val),len(mri_imgs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: View image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:57.826373Z",
     "start_time": "2021-06-14T16:20:55.846926Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(mri_imgs_train[0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:20:58.946205Z",
     "start_time": "2021-06-14T16:20:57.829390Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation.plot_slices(mri_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Implementation, configuration, and evaluation of the experiment.\n",
    "\n",
    "### Train Deep Model 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:32:18.461681Z",
     "start_time": "2021-06-14T16:32:17.555797Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=82dd7cc658674068aba0821c0502696c\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 'infinite', 'endTime': None, 'id': '82dd7cc658674068aba0821c0502696c', 'lastUpdateTime': None, 'maxCombo': 0, 'name': '82dd7cc658674068aba0821c0502696c', 'parameters': {'criterion_weights': {'max': 10000, 'min': 1, 'scalingType': 'loguniform', 'type': 'integer'}, 'dropout': {'max': 0.5, 'min': 0.1, 'scalingType': 'loguniform', 'type': 'float'}, 'learning_rate': {'max': 100.0, 'min': 1e-10, 'scalingType': 'loguniform', 'type': 'float'}, 'scheduler': {'type': 'categorical', 'values': ['ReduceLROnPlateau', '']}, 'weight_decay': {'max': 0.9, 'min': 1e-10, 'scalingType': 'loguniform', 'type': 'float'}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 0, 'metric': 'train_bal_acc', 'minSampleSize': 100, 'objective': 'maximize', 'retryAssignLimit': 0, 'retryLimit': 1000}, 'startTime': 14307810832, 'state': {'mode': None, 'seed': None, 'sequence': [], 'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0, 'sequence_retry_count': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '2.0.1'}\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Optimizer\n",
    "\n",
    "artifacts = {\n",
    "    #\"train_data\": (mri_imgs_train, labels_train),\n",
    "    #\"val_data\": (mri_imgs_val, labels_val),\n",
    "    \"test_data\": (mri_imgs_test, labels_test)\n",
    "}\n",
    "\n",
    "# Define parameter configuration for experiment run\n",
    "params = {\n",
    "    \"batch_size\": 3,\n",
    "    \"epochs\": 100,\n",
    "    \"es_patience\": None, # None = deactivate early stopping\n",
    "    \"model_name\": 'Attention_Unet',\n",
    "    \"optimizer_momentum\": 0.9,\n",
    "    \"optimizer\":'Adam',\n",
    "    \"criterion\": \"CrossEntropyLoss\",\n",
    "    \"sampler\": None,   #'ImbalancedDatasetSampler2',\n",
    "    \"shuffle_train_set\": True,\n",
    "    \"save_models\":True,\n",
    "    \"debug\": True,\n",
    "    \"criterion_weights\": 100,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"weight_decay\": 1e-3,\n",
    "}\n",
    "\n",
    "params.update(dataset_params)\n",
    "params.update(preprocessing_params)\n",
    "\n",
    "config = {\n",
    "    # We pick the Bayes algorithm:\n",
    "    \"algorithm\": \"bayes\",\n",
    "    # Declare your hyperparameters in the Vizier-inspired format:\n",
    "    \"parameters\": {\n",
    "       \"criterion_weights\": {\"type\": \"integer\", \"scalingType\": \"loguniform\", \"min\": 1, \"max\": 10000},\n",
    "       \"dropout\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 0.1, \"max\": 0.5},\n",
    "       \"learning_rate\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-10, \"max\": 1e2},\n",
    "        \"scheduler\": {\"type\": \"categorical\", \"values\": [\"ReduceLROnPlateau\", \"\"]},\n",
    "         \"weight_decay\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-10, \"max\": 9e-1},\n",
    "    },\n",
    "    # Declare what we will be optimizing, and how:\n",
    "    \"spec\": {\"metric\": \"train_bal_acc\", \"objective\": \"maximize\"},  #test balance accuracy\n",
    "}\n",
    "\n",
    "\n",
    "opt = Optimizer(config, api_key=env.cached_data[\"comet_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-14T16:32:20.216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, get experiments, and train your models:\n",
    "for comet_exp in opt.get_experiments(project_name=env.project + \"-\" + params[\"prediction\"]):\n",
    "    print(comet_exp)\n",
    "    param_copy = params.copy()\n",
    "    comet_exp.params\n",
    "    \n",
    "    param_copy[\"dropout\"] = comet_exp.get_parameter(\"dropout\")\n",
    "    param_copy[\"criterion_weights\"] = comet_exp.get_parameter(\"criterion_weights\")\n",
    "    param_copy[\"learning_rate\"] = comet_exp.get_parameter(\"learning_rate\")\n",
    "    param_copy[\"scheduler\"] = comet_exp.get_parameter(\"scheduler\")\n",
    "    param_copy[\"weigtht_decay\"] = comet_exp.get_parameter(\"weight_decay\")\n",
    "\n",
    "    exp = env.create_experiment(\n",
    "        params[\"prediction\"] + \"-pytorch-\" + params[\"model_name\"], comet_exp\n",
    "    ) #params[\"selected_label\"] + \"-hyperopt-\" + params[\"model_name\"]\n",
    "    exp.run(training.train_pytorch_model, param_copy, artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test tomorrow old voxel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Do evaluation, e.g. visualizations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:09:17.968495Z",
     "start_time": "2021-06-14T16:09:17.908417Z"
    }
   },
   "outputs": [],
   "source": [
    "from aneurysm_utils.utils.pytorch_utils import predict\n",
    "from aneurysm_utils.models.attention_unet import unet_grid_attention_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:09:18.031932Z",
     "start_time": "2021-06-14T16:09:17.970615Z"
    }
   },
   "outputs": [],
   "source": [
    "model = exp.artifacts[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = unet_grid_attention_3D(feature_scale=4, n_classes=2, is_deconv=True, in_channels=1,\n",
    "                 nonlocal_mode='concatenation', attention_dsample=(2,2,2), is_batchnorm=True)\n",
    "PATH = \"/group/cake/our-git-project/experiments/2021-07-05-23-19-28_mask-pytorch-attention-unet/Attention_Unet_Attention_Unet_45000.pt\"\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:09:18.677667Z",
     "start_time": "2021-06-14T16:09:18.033816Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'num_threads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-7330ff9fd738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# TODO: use fixed batch size of 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'num_threads'"
     ]
    }
   ],
   "source": [
    "from aneurysm_utils.utils import pytorch_utils\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "test_dataset = pytorch_utils.PytorchDataset(\n",
    "                mri_imgs_test,\n",
    "                labels_test,\n",
    "                dtype=np.float64,\n",
    "                \n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=1,  # TODO: use fixed batch size of 5\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "predictions = predict(model, test_loader, apply_softmax=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = map(lambda x: x[0], predictions)\n",
    "preds = list(converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, list)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "\n",
    "datafile = TemporaryFile()\n",
    "np.save(datafile,arr = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:09:18.684680Z",
     "start_time": "2021-06-14T16:00:27.594Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(pred_classes[0][0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T16:09:18.688545Z",
     "start_time": "2021-06-14T16:00:27.596Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(labels_test[0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Working env",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
