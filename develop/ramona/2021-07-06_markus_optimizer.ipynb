{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Template\n",
    "\n",
    "\n",
    "**In this notebook:**\n",
    "\n",
    "* Template with comet ml optimizer \n",
    "\n",
    "**Todo:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "Install, load, and initialize all required dependencies for this experiment.\n",
    "\n",
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:15.377488Z",
     "start_time": "2021-07-06T16:34:21.309592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#It should be possible to run the notebook independent of anything else. \n",
    "# If dependency cannot be installed via pip, either:\n",
    "# - download & install it via %%bash\n",
    "# - atleast mention those dependecies in this section\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q -e ../../utils/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:22.495358Z",
     "start_time": "2021-07-06T16:35:15.380282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext memory_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Recursion Depth\n",
    "sys.setrecursionlimit(1000000000)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import comet_ml\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn.plotting as nip\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import collections\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "%config InlineBackend.figure_format='retina'  # adapt plots for retina displays\n",
    "import git\n",
    "\n",
    "\n",
    "# Project utils\n",
    "\n",
    "import aneurysm_utils\n",
    "from aneurysm_utils import evaluation, training,preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:22.550172Z",
     "start_time": "2021-07-06T16:35:22.497844Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"workspace\" in os.getcwd():\n",
    "    ROOT = \"/workspace\" # local \n",
    "elif \"/group/cake\" in os.getcwd(): \n",
    "    ROOT = \"/group/cake\" # Jupyter Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:22.618677Z",
     "start_time": "2021-07-06T16:35:22.552658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Info:\n",
      "\n",
      "Library Version: 0.1.0\n",
      "Configured Project: our-git-project\n",
      "\n",
      "Folder Structure: \n",
      "- Root folder: /workspace\n",
      " - Project folder: /workspace/our-git-project\n",
      " - Datasets folder: /workspace/our-git-project/datasets\n",
      " - Models folder: /workspace/our-git-project/models\n",
      " - Experiments folder: /workspace/our-git-project/experiments\n"
     ]
    }
   ],
   "source": [
    "env = aneurysm_utils.Environment(project=\"our-git-project\", root_folder=ROOT)\n",
    "env.cached_data[\"comet_key\"] = \"EGrR4luSis87yhHbs2rEaqAWs\" \n",
    "env.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Download, explore, and prepare all required data for the experiment in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:22.687000Z",
     "start_time": "2021-07-06T16:35:22.622657Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    \"prediction\": \"mask\",\n",
    "    \"mri_data_selection\": \"\", \n",
    "    \"balance_data\": False,\n",
    "    \"seed\": 1,\n",
    "    \"resample_voxel_dim\": (1, 1, 1)\n",
    "}\n",
    "\n",
    "preprocessing_params = {\n",
    "    'min_max_normalize': True,\n",
    "    'mean_std_normalize': False,\n",
    "    'smooth_img': False, # can contain a number: smoothing factor\n",
    "    'intensity_segmentation': 0.15\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:22.906664Z",
     "start_time": "2021-07-06T16:35:22.689990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aneurysm Geometry</th>\n",
       "      <th>Angiography Data</th>\n",
       "      <th>Vessel Geometry</th>\n",
       "      <th>Labeled Mask Index</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Rupture Status</th>\n",
       "      <th>Age Bin</th>\n",
       "      <th>Aneurysm Count</th>\n",
       "      <th>Case</th>\n",
       "      <th>Path Orig</th>\n",
       "      <th>Path Mask</th>\n",
       "      <th>Path Vessel</th>\n",
       "      <th>Path Labeled Mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001.stl</td>\n",
       "      <td>A001_orig.nii.gz</td>\n",
       "      <td>A001_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>Acom</td>\n",
       "      <td>48</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A001</td>\n",
       "      <td>/workspace/our-git-project/datasets/A001_orig....</td>\n",
       "      <td>/workspace/our-git-project/datasets/A001_masks...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A001_vesse...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A001_label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A003.stl</td>\n",
       "      <td>A003_orig.nii.gz</td>\n",
       "      <td>A003_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>Pcom</td>\n",
       "      <td>58</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>1</td>\n",
       "      <td>A003</td>\n",
       "      <td>/workspace/our-git-project/datasets/A003_orig....</td>\n",
       "      <td>/workspace/our-git-project/datasets/A003_masks...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A003_vesse...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A003_label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A005.stl</td>\n",
       "      <td>A005_orig.nii.gz</td>\n",
       "      <td>A005_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>PICA</td>\n",
       "      <td>45</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A005</td>\n",
       "      <td>/workspace/our-git-project/datasets/A005_orig....</td>\n",
       "      <td>/workspace/our-git-project/datasets/A005_masks...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A005_vesse...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A005_label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A006.stl</td>\n",
       "      <td>A006_orig.nii.gz</td>\n",
       "      <td>A006_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>ACom</td>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>1</td>\n",
       "      <td>A006</td>\n",
       "      <td>/workspace/our-git-project/datasets/A006_orig....</td>\n",
       "      <td>/workspace/our-git-project/datasets/A006_masks...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A006_vesse...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A006_label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A008.stl</td>\n",
       "      <td>A008_orig.nii.gz</td>\n",
       "      <td>A008_vessel.stl</td>\n",
       "      <td>1</td>\n",
       "      <td>ACA</td>\n",
       "      <td>72</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(70, 80]</td>\n",
       "      <td>1</td>\n",
       "      <td>A008</td>\n",
       "      <td>/workspace/our-git-project/datasets/A008_orig....</td>\n",
       "      <td>/workspace/our-git-project/datasets/A008_masks...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A008_vesse...</td>\n",
       "      <td>/workspace/our-git-project/datasets/A008_label...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Aneurysm Geometry  Angiography Data  Vessel Geometry  Labeled Mask Index  \\\n",
       "0          A001.stl  A001_orig.nii.gz  A001_vessel.stl                   1   \n",
       "1          A003.stl  A003_orig.nii.gz  A003_vessel.stl                   1   \n",
       "2          A005.stl  A005_orig.nii.gz  A005_vessel.stl                   1   \n",
       "3          A006.stl  A006_orig.nii.gz  A006_vessel.stl                   1   \n",
       "4          A008.stl  A008_orig.nii.gz  A008_vessel.stl                   1   \n",
       "\n",
       "  Location  Age Sex  Rupture Status   Age Bin  Aneurysm Count  Case  \\\n",
       "0     Acom   48   m             1.0  (40, 50]               1  A001   \n",
       "1     Pcom   58   f             0.0  (50, 60]               1  A003   \n",
       "2     PICA   45   m             1.0  (40, 50]               1  A005   \n",
       "3     ACom   46   f             1.0  (40, 50]               1  A006   \n",
       "4      ACA   72   f             0.0  (70, 80]               1  A008   \n",
       "\n",
       "                                           Path Orig  \\\n",
       "0  /workspace/our-git-project/datasets/A001_orig....   \n",
       "1  /workspace/our-git-project/datasets/A003_orig....   \n",
       "2  /workspace/our-git-project/datasets/A005_orig....   \n",
       "3  /workspace/our-git-project/datasets/A006_orig....   \n",
       "4  /workspace/our-git-project/datasets/A008_orig....   \n",
       "\n",
       "                                           Path Mask  \\\n",
       "0  /workspace/our-git-project/datasets/A001_masks...   \n",
       "1  /workspace/our-git-project/datasets/A003_masks...   \n",
       "2  /workspace/our-git-project/datasets/A005_masks...   \n",
       "3  /workspace/our-git-project/datasets/A006_masks...   \n",
       "4  /workspace/our-git-project/datasets/A008_masks...   \n",
       "\n",
       "                                         Path Vessel  \\\n",
       "0  /workspace/our-git-project/datasets/A001_vesse...   \n",
       "1  /workspace/our-git-project/datasets/A003_vesse...   \n",
       "2  /workspace/our-git-project/datasets/A005_vesse...   \n",
       "3  /workspace/our-git-project/datasets/A006_vesse...   \n",
       "4  /workspace/our-git-project/datasets/A008_vesse...   \n",
       "\n",
       "                                   Path Labeled Mask  \n",
       "0  /workspace/our-git-project/datasets/A001_label...  \n",
       "1  /workspace/our-git-project/datasets/A003_label...  \n",
       "2  /workspace/our-git-project/datasets/A005_label...  \n",
       "3  /workspace/our-git-project/datasets/A006_label...  \n",
       "4  /workspace/our-git-project/datasets/A008_label...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aneurysm_utils.data_collection import load_aneurysm_dataset\n",
    "\n",
    "df = load_aneurysm_dataset(\n",
    "    env,\n",
    "    mri_data_selection=dataset_params[\"mri_data_selection\"],\n",
    "    random_state=dataset_params[\"seed\"]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Split MRI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.449358Z",
     "start_time": "2021-07-06T16:35:22.910271Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "98\n",
      "         Images\n",
      "-----  --------\n",
      "All         109\n",
      "Train        87\n",
      "Val          11\n",
      "Test         11\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "istarmap() missing 1 required positional argument: 'iterable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-97b1a05e0286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = df.loc[df[\"Case\"].isin(case_list)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_data, test_data, val_data, _ = split_mri_images(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/our-git-project/utils/aneurysm_utils/data_collection.py\u001b[0m in \u001b[0;36msplit_mri_images\u001b[0;34m(env, df, prediction, test_size, validation_size, encode_labels, balance_data, random_state, print_stats, resample_voxel_dim, resample_size, order)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     return (\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mload_mri_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mload_mri_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mload_mri_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_voxel_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/our-git-project/utils/aneurysm_utils/data_collection.py\u001b[0m in \u001b[0;36mload_mri_images\u001b[0;34m(env, df, prediction, mask, case_list, resample_voxel_dim, resample_size, order)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistarmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mistarmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     data_outputs = list(\n\u001b[0;32m--> 186\u001b[0;31m         tqdm(pool.istarmap(load_mri_image, input_for_pool), total=len(input_for_pool)))\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mmri_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: istarmap() missing 1 required positional argument: 'iterable'"
     ]
    }
   ],
   "source": [
    "# Load MRI images and split into train, test, and validation\n",
    "from aneurysm_utils.data_collection import split_mri_images\n",
    "#case_list = [ \"A123\", \"A121\", \"A124\"] # \"A003\",\"A005\",\"A006\",\"A008\", \"A010\", \"A012\",\"A009\", \"A120\",\n",
    "#df = df.loc[df[\"Case\"].isin(case_list)]\n",
    "\n",
    "train_data, test_data, val_data, _ = split_mri_images(\n",
    "    env, \n",
    "    df, \n",
    "    prediction=dataset_params[\"prediction\"], \n",
    "    encode_labels=False,\n",
    "    random_state=dataset_params[\"seed\"],\n",
    "    balance_data=dataset_params[\"balance_data\"],\n",
    "    resample_voxel_dim=dataset_params[\"resample_voxel_dim\"]\n",
    ")\n",
    "\n",
    "mri_imgs_train, labels_train = train_data\n",
    "mri_imgs_test, labels_test = test_data\n",
    "mri_imgs_val, labels_val = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.453812Z",
     "start_time": "2021-07-06T16:34:21.256Z"
    }
   },
   "outputs": [],
   "source": [
    "from aneurysm_utils import preprocessing\n",
    "\n",
    "most_commen_shape = preprocessing.check_mri_shapes(mri_imgs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.455083Z",
     "start_time": "2021-07-06T16:34:21.259Z"
    }
   },
   "outputs": [],
   "source": [
    "size = most_commen_shape  #(139, 139, 120)\n",
    "train_index = [i for i, e in enumerate(mri_imgs_train) if e.shape != size]\n",
    "mri_imgs_train = [i for j, i in enumerate(mri_imgs_train) if j not in train_index]\n",
    "labels_train = [i for j, i in enumerate(labels_train) if j not in train_index]\n",
    "\n",
    "test_index = [i for i, e in enumerate(mri_imgs_test) if e.shape != size]\n",
    "mri_imgs_test = [i for j, i in enumerate(mri_imgs_test) if j not in test_index]\n",
    "labels_test = [i for j, i in enumerate(labels_test) if j not in test_index]\n",
    "\n",
    "val_index = [i for i, e in enumerate(mri_imgs_val) if e.shape != size]\n",
    "mri_imgs_val = [i for j, i in enumerate(mri_imgs_val) if j not in val_index]\n",
    "labels_val = [i for j, i in enumerate(labels_val) if j not in val_index]\n",
    "\n",
    "mri_imgs_train[0].shape\n",
    "preprocessing.check_mri_shapes(mri_imgs_train)\n",
    "print(np.unique(labels_val[0], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.457750Z",
     "start_time": "2021-07-06T16:34:21.261Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_creater(image, patch_size):\n",
    "    \"\"\"\n",
    "    Creates overlapping patches from  preprocessed image, the number of patches is fixed to certain value\n",
    "    and the size can be changed as well\n",
    "    ----------\n",
    "    image: numpy.array\n",
    "        image which will be sliced into patches\n",
    "    patch_size: tuple of int\n",
    "        size of the patch, equal in each direction\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array  (n_patches,channels,patch_size,patch_size,patch_size)\n",
    "        list containing the patches\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    dim = np.array(image.shape)# size of the image\n",
    "    n_patches = np.ceil(dim/patch_size).astype(int) # calculates the number of patches for each dim, to cover all voxel at least once\n",
    "    rest  = n_patches * patch_size%dim ## calculates the remaining voxel which are going to overlap \n",
    "\n",
    "    patches = []\n",
    "    for i in range(n_patches[0]):\n",
    "        \n",
    "        if i == n_patches[0]-1: ## only the last cube is an overlapped cube\n",
    "            start_x = i*patch_size-rest[0]## indices were to start and stop the slicing true the image array\n",
    "            stop_x= (i+1)* patch_size-rest[0]\n",
    "              \n",
    "        else:    \n",
    "            start_x = i*patch_size\n",
    "            stop_x = (i+1)* patch_size\n",
    "\n",
    "        \n",
    "              \n",
    "        for j in range(n_patches[1]):\n",
    "            if j == n_patches[1]-1: ## only the last cube is an overlapped cube\n",
    "                start_y = j*patch_size-rest[1]\n",
    "                stop_y= (j+1)* patch_size-rest[1]\n",
    "              \n",
    "            else:    \n",
    "                start_y = j*patch_size\n",
    "                stop_y = (j+1)* patch_size\n",
    "            \n",
    "            for k in range(n_patches[2]):\n",
    "                if k == n_patches[2]-1: \n",
    "                    start_z = k*patch_size-rest[2]\n",
    "                    stop_z = (k+1)* patch_size-rest[2]\n",
    "              \n",
    "                else:    \n",
    "                    start_z = k*patch_size\n",
    "                    stop_z = (k+1)* patch_size\n",
    "\n",
    "              \n",
    "                patches.append(image[start_x:stop_x,start_y:stop_y,start_z:stop_z])\n",
    "        \n",
    "        \n",
    "    #return np.array([*patches])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.460506Z",
     "start_time": "2021-07-06T16:34:21.263Z"
    }
   },
   "outputs": [],
   "source": [
    "def patch_list(data,patch_size):\n",
    "    \"\"\"\n",
    "    data: numpy.array\n",
    "        containing dataset of dimensions (size_of_set,height,width,depth),e.g. (75,139,139,120)\n",
    "    patch_size: int\n",
    "    \n",
    "    Return\n",
    "    \n",
    "    list_patch: list\n",
    "        each element is one image of type numpy.array/torch.tensor with dimensions(n_classes,most_common_shape),\n",
    "    \"\"\"\n",
    "    list_patch = []\n",
    "\n",
    "    for n in range(len(data)):\n",
    "        patch = patch_creater(data[n],patch_size)\n",
    "        list_patch = list_patch+patch\n",
    "    \n",
    "\n",
    "    return list_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.463374Z",
     "start_time": "2021-07-06T16:34:21.265Z"
    }
   },
   "outputs": [],
   "source": [
    "from aneurysm_utils import preprocessing\n",
    "patch_size = 64\n",
    "size_of_train = len(mri_imgs_train)\n",
    "size_of_test = len(mri_imgs_test)\n",
    "size_of_val = len(mri_imgs_val)\n",
    "\n",
    "# preprocess all lists as one to have a working mean_std_normalization\n",
    "mri_imgs = mri_imgs_train + mri_imgs_test + mri_imgs_val\n",
    "mri_imgs = preprocessing.preprocess(env, mri_imgs, preprocessing_params)\n",
    "###creating patches\n",
    "mri_imgs_train = np.asarray(mri_imgs[:size_of_train])\n",
    "mri_imgs_train = patch_list(mri_imgs_train,patch_size)\n",
    "mri_imgs_test = np.asarray(mri_imgs[size_of_train : size_of_train + size_of_test])\n",
    "mri_imgs_test = patch_list(mri_imgs_test,patch_size)\n",
    "mri_imgs_val = np.asarray(mri_imgs[size_of_train + size_of_test :])\n",
    "mri_imgs_val = patch_list(mri_imgs_val,patch_size)\n",
    "\n",
    "# preprocess mask\n",
    "x, y, h = labels_train[0].shape\n",
    "labels_train = patch_list(labels_train,patch_size)\n",
    "labels_test = patch_list(labels_test,patch_size)\n",
    "labels_val = patch_list(labels_val,patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.465785Z",
     "start_time": "2021-07-06T16:34:21.267Z"
    }
   },
   "outputs": [],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.467733Z",
     "start_time": "2021-07-06T16:34:21.268Z"
    }
   },
   "outputs": [],
   "source": [
    "mri_imgs_train[0].shape,len(mri_imgs_train),type(mri_imgs_test),len(mri_imgs_test),type(mri_imgs_val),len(mri_imgs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: View image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.472815Z",
     "start_time": "2021-07-06T16:34:21.274Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(mri_imgs_train[0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Implementation, configuration, and evaluation of the experiment.\n",
    "\n",
    "### Train Deep Model 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.475691Z",
     "start_time": "2021-07-06T16:34:21.276Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from comet_ml import Optimizer\n",
    "\n",
    "artifacts = {\n",
    "    \"train_data\": (mri_imgs_train[:20], labels_train[:20]),\n",
    "    \"val_data\": (mri_imgs_val[:18], labels_val[:18]),\n",
    "    \"test_data\": (mri_imgs_test[:18], labels_test[:18])\n",
    "}\n",
    "\n",
    "# Define parameter configuration for experiment run\n",
    "params = {\n",
    "    \"batch_size\": 3,\n",
    "    \"epochs\": 5,\n",
    "    \"es_patience\": None, # None = deactivate early stopping\n",
    "    \"model_name\": 'Attention_Unet',\n",
    "    \"optimizer_momentum\": 0.9,\n",
    "    \"optimizer\":'Adam',\n",
    "    \"criterion\": \"CrossEntropyLoss\",\n",
    "    \"sampler\": None,   #'ImbalancedDatasetSampler2',\n",
    "    \"shuffle_train_set\": True,\n",
    "    \"save_models\":True,\n",
    "    \"debug\": True,\n",
    "    \"criterion_weights\": 100,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"weight_decay\": 1e-3,\n",
    "}\n",
    "\n",
    "params.update(dataset_params)\n",
    "params.update(preprocessing_params)\n",
    "\n",
    "config = {\n",
    "    # We pick the Bayes algorithm:\n",
    "    \"algorithm\": \"bayes\",\n",
    "    # Declare your hyperparameters in the Vizier-inspired format:\n",
    "    \"parameters\": {\n",
    "       \"criterion_weights\": {\"type\": \"integer\", \"scalingType\": \"loguniform\", \"min\": 1, \"max\": 10000},\n",
    "       \"dropout\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 0.1, \"max\": 0.5},\n",
    "       \"learning_rate\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-10, \"max\": 1e-2},\n",
    "        \"scheduler\": {\"type\": \"categorical\", \"values\": [\"ReduceLROnPlateau\", \"\"]},\n",
    "         \"weight_decay\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-10, \"max\": 9e-1},\n",
    "    },\n",
    "    # Declare what we will be optimizing, and how:\n",
    "    \"spec\": {\"metric\": \"train_bal_acc\", \"objective\": \"maximize\"},  #test balance accuracy\n",
    "}\n",
    "\n",
    "\n",
    "opt = Optimizer(config, api_key=env.cached_data[\"comet_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.477283Z",
     "start_time": "2021-07-06T16:34:21.280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, get experiments, and train your models:\n",
    "for comet_exp in opt.get_experiments(project_name=env.project + \"-\" + params[\"prediction\"]):\n",
    "    print(comet_exp)\n",
    "    param_copy = params.copy()\n",
    "    comet_exp.params\n",
    "    \n",
    "    param_copy[\"dropout\"] = comet_exp.get_parameter(\"dropout\")\n",
    "    param_copy[\"criterion_weights\"] = comet_exp.get_parameter(\"criterion_weights\")\n",
    "    param_copy[\"learning_rate\"] = comet_exp.get_parameter(\"learning_rate\")\n",
    "    param_copy[\"scheduler\"] = comet_exp.get_parameter(\"scheduler\")\n",
    "    param_copy[\"weigtht_decay\"] = comet_exp.get_parameter(\"weight_decay\")\n",
    "\n",
    "    exp = env.create_experiment(\n",
    "        params[\"prediction\"] + \"-pytorch-\" + params[\"model_name\"], comet_exp\n",
    "    ) #params[\"selected_label\"] + \"-hyperopt-\" + params[\"model_name\"]\n",
    "    exp.run(training.train_pytorch_model, param_copy, artifacts)\n",
    "\n",
    "    time.sleep(3)\n",
    "    del exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.479091Z",
     "start_time": "2021-07-06T16:34:21.282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "\n",
    "  \n",
    "\n",
    "print('RAM memory % used:', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.480491Z",
     "start_time": "2021-07-06T16:34:21.285Z"
    }
   },
   "outputs": [],
   "source": [
    "#test tomorrow old voxel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Do evaluation, e.g. visualizations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.482267Z",
     "start_time": "2021-07-06T16:34:21.288Z"
    }
   },
   "outputs": [],
   "source": [
    "from aneurysm_utils.utils.pytorch_utils import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.483947Z",
     "start_time": "2021-07-06T16:34:21.290Z"
    }
   },
   "outputs": [],
   "source": [
    "model = exp.artifacts[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.484972Z",
     "start_time": "2021-07-06T16:34:21.292Z"
    }
   },
   "outputs": [],
   "source": [
    "from aneurysm_utils.utils import pytorch_utils\n",
    "if params['model_name'] ==\"SegNet\":\n",
    "    test_dataset = pytorch_utils.PyTorchGeometricDataset(\n",
    "            mri_images=mri_imgs_test,\n",
    "            labels=labels_test,\n",
    "            root=env.project_folder,\n",
    "            split=\"test\",\n",
    "        )\n",
    "else:\n",
    "    test_dataset = pytorch_utils.PytorchDataset(\n",
    "                mri_imgs_test,\n",
    "                labels_test,\n",
    "                dtype=np.float64,\n",
    "                segmentation=params.segmentation,\n",
    "            )\n",
    "\n",
    "predictions = predict(model, test_dataset, apply_softmax=False )\n",
    "if params['model_name'] == \"SegNet\":\n",
    "    pred_classes, pred_scores = extend_point_cloud(\n",
    "                    predictions[0], predictions[1], test_dataset, labels_test\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.486966Z",
     "start_time": "2021-07-06T16:34:21.294Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(preds_out,arr = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.490547Z",
     "start_time": "2021-07-06T16:34:21.299Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(pred_classes[0][0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T16:35:23.492468Z",
     "start_time": "2021-07-06T16:34:21.300Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "nip.view_img(\n",
    "    nib.Nifti1Image(labels_test[0], np.eye(4)),\n",
    "    symmetric_cmap=False,\n",
    "    cmap=\"Greys_r\",\n",
    "    bg_img=False,\n",
    "    black_bg=True,\n",
    "    threshold=1e-03, \n",
    "    draw_cross=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
