{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a492f5",
   "metadata": {},
   "source": [
    "# Create Prediction with Segmentation Model\n",
    "\n",
    "## Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908846c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging, os, sys\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Re-import packages if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Recursion Depth\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "# Intialize tqdm to always use the notebook progress bar\n",
    "import tqdm\n",
    "tqdm.tqdm = tqdm.tqdm_notebook\n",
    "\n",
    "# Third-party libraries\n",
    "import comet_ml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn.plotting as nip\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "import git\n",
    "\n",
    "\n",
    "# Project utils\n",
    "\n",
    "import aneurysm_utils\n",
    "from aneurysm_utils import evaluation, training,preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d22a8",
   "metadata": {},
   "source": [
    "## Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5695e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"workspace\" in os.getcwd():\n",
    "    ROOT = \"/workspace\"\n",
    "elif \"/group/cake\" in os.getcwd(): \n",
    "    ROOT = \"/group/cake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = aneurysm_utils.Environment(project=\"our-git-project\", root_folder=ROOT)\n",
    "env.cached_data[\"comet_key\"] = \"EGrR4luSis87yhHbs2rEaqAWs\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb439d43",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ba9389",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_params = {\n",
    "    'min_max_normalize': True,\n",
    "    'mean_std_normalize': False,\n",
    "    'smooth_img': False, # can contain a number: smoothing factor\n",
    "    'intensity_segmentation': 0.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0a401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing: Min Max Normalize...\n",
      "[INFO] Preprocessing: Intensity Segmentation...\n"
     ]
    }
   ],
   "source": [
    "#Creates list of mri_imgs to create predictions\n",
    "#case_list_shuffled is the list of the cases of the test set after the train/test split with random seed 1 \n",
    "#should be changed with other split or other test set\n",
    "\n",
    "from aneurysm_utils import postprocessing\n",
    "case_list_shuffled=[\"A130_R\",\"A118\",\"A120\",\"A115\",\"A133\",\"A073\",\"A072\",\"A077\",\"A064\"]\n",
    "mri_imgs_test=[]\n",
    "\n",
    "for cases in case_list_shuffled:\n",
    "    file_path=f\"../../../../data/training/{cases}_orig.nii.gz\"\n",
    "    mri_imgs_test.append(nib.load(file_path).get_fdata())\n",
    "\n",
    "    #preprocess the images \n",
    "mri_imgs_test=postprocessing.resample(mri_imgs_test,(70,70,60))\n",
    "mri_imgs_test=preprocessing.preprocess(env,mri_imgs_test,preprocessing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358d6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads labels \n",
    "from aneurysm_utils import postprocessing\n",
    "case_list_shuffled=[\"A130_R\",\"A118\",\"A120\",\"A115\",\"A133\",\"A073\",\"A072\",\"A077\",\"A064\"]\n",
    "labels_test=[]\n",
    "\n",
    "for cases in case_list_shuffled:\n",
    "    file_path=f\"../../../../data/training/{cases}_masks.nii.gz\"\n",
    "    labels_test.append(nib.load(file_path).get_fdata())\n",
    "#resampling the labels to the correct size\n",
    "labels_test=postprocessing.resample(labels_test,(70,70,60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd9730",
   "metadata": {},
   "source": [
    "## Predict with Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4cf5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aneurysm_utils.utils.pytorch_utils import predict\n",
    "from aneurysm_utils.models.pointnet  import SegNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755ffa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loads the trained modelfile\n",
    "model = SegNet(dropout=0.38, num_classes=2, sample_rate1 =0.2263, sample_rate2 =0.2941,start_radius =7.254)\n",
    "PATH = \"/group/cake/our-git-project/models/SegNet_SegNet_3000.pt\"\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "#test = model()\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6efa8228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "/group/cake/our-git-project/processed/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "#Creates the dataset of the images and labels\n",
    "from aneurysm_utils.utils import pytorch_utils\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "test_dataset = pytorch_utils.PyTorchGeometricDataset(\n",
    "                mri_images=mri_imgs_test,\n",
    "                labels=labels_test,\n",
    "                root=\"/group/cake/our-git-project/processed\",\n",
    "                split=\"test\",\n",
    "                force_processing=True            \n",
    "            )\n",
    "\n",
    "del mri_imgs_test,labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the predictions\n",
    "from torch_geometric.data import DataLoader as DataLoaderGeometric\n",
    "test_loader = DataLoaderGeometric(\n",
    "            test_dataset,\n",
    "            batch_size=1,  # TODO: use fixed batch size of 5\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "predictions = predict(model, test_loader, apply_softmax=False,ispointnet=True,dimension=(70, 70, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d6dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves predicted masks in prediction folder\n",
    "np.save(\"/group/cake/our-git-project/predictions/pointnet_2.npy\",predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab_nine_terminal",
   "language": "python",
   "name": "exploration-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
